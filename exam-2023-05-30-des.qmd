---
title: 2023-05-30 <br>Descriptive Statistics and Regression
date: 2023-05-30
lang: en
---

```{r setup, echo = F}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```

```{r libraries, echo = F}
library(tidyverse)
library(kableExtra)
```

:::{#exr-1}
```{r echo=FALSE, results="hide"}
## DATA GENERATION
library(knitr)
knitr::opts_chunk$set(echo = F, message = F, warning = F)
library(tidyverse)
library(kableExtra)
df <- tibble(
    `Failed subjects` = c(0, 1, 2, 3, 4, 5, 6, 8), 
    `Previous year course` = c(7, 15, 11, 5, 4, 2, 1, 0), 
    `Current course` = c(8, 12, 8, 7, 3, 2, 2, 1))
# QUESTION/ANSWER GENERATION
x <- rep(df$`Failed subjects`, df$`Previous year course`)
y <- rep(df$`Failed subjects`, df$`Current course`)
# Tamaño de la muestra
nx <- length(x)
ny <- length(y)
# Media
mx <- mean(x)
my <- mean(y)
# Varianza
s2x <- sum(x^2)/nx-mx^2
s2y <- sum(y^2)/ny-my^2
# Desviación típica
sx <- sqrt(s2x)
sy <- sqrt(s2y)
# Coef. variación
cvx <- sx/mx
cvy <- sy/my
# Coef. asimetría
g1x <- sum((x-mx)^3)/(nx*sx^3)
g1y <- sum((y-my)^3)/(ny*sy^3)
# Coef. apuntamiento
g2x <- sum((x-mx)^4)/(nx*sx^4)-3
g2y <- sum((y-my)^4)/(ny*sy^4)-3
# Puntuaciones típicas
zx <- (6-mx)/sx
zy <- (7-my)/sy
```

To see if the confinement due to COVID-19 influenced the performance of a course, the number of failed subjects of each student in the current course and in the previous year course has been counted, obtaining the table below.

```{r echo=FALSE}
kable(df) %>% kable_styling()
```

a.  Draw the box plots of the failed subjects in the current and the previous year courses and compare them.

a.  Can we assume that both samples come from a normal population?

a.  In which sample is the mean more representative?

a.  Which number of failed subjects is relatively greater, 7 in the current course or 6 in the previous year course?


Use the following sums for the computations:  
Previous year course: $\sum x_i=`r sum(x)`$ subjects, $\sum x_i^2=`r sum(x^2)`$ subjects$^2$, $\sum (x_i-\bar x)^3=`r round(sum((x-mx)^3),2)`$ subjects$^3$ y $\sum (x_i-\bar x)^4=`r round(sum((x-mx)^4),2)`$  subjects$^4$.  
Current course: $\sum x_i=`r sum(y)`$ subjects, $\sum x_i^2=`r sum(y^2)`$ subjects$^2$, $\sum (x_i-\bar x)^3=`r round(sum((y-my)^3),2)`$ subjects$^3$ y $\sum (x_i-\bar x)^4=`r round(sum((y-my)^4),2)`$  subjects$^4$.  

:::{.callout-tip collapse="true"}
## Solution
a.  Box plot

```{r box-plot}
tibble(Course = c(rep("Previous year course", nx), rep("Current course", ny)), `Failed subjects` = c(x, y))  %>%  
    ggplot(aes(x = Course, y = `Failed subjects`)) +
    geom_boxplot()
```

a.  Previous year course: $\bar x = `r round(mx, 4)`$ subjects, $s_x^2=`r round(s2x,4)`$ subjects$^2$, $s_x=`r round(sx,4)`$ subjects, $g_1 = `r round(g1x,4)`$ and $g_2 = `r round(g2x,4)`$.  
Current course: $\bar x = `r round(my, 4)`$ subjects, $s_x^2=`r round(s2y,4)`$ subjects$^2$, $s_x=`r round(sy,4)`$ subjects, $g_1 = `r round(g1y,4)`$ and $g_2 = `r round(g2y,4)`$.  
In both courses the coefficients of skewness and kurtosis are between -2 and 2, so we can assume that both samples come from a normal population.

a.  Previous year course: $cv = `r round(cvx, 4)`$.  
Current year course: $cv = `r round(cvy, 4)`$.  
As the coefficient of variation of the previous year course is smaller, its mean is a little bit more representative.

a.  Previous year course: $z(6) = `r round(zx, 4)`$.  
Current course: $z(7) = `r round(zy, 4)`$.  
Thus, 6 failed subjects is relative greater in the previous year course than 7 failed subjects in the current course.
:::
:::

:::{#exr-2}
```{r echo=FALSE, results="hide"}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
options(scipen=999)
library(kableExtra)
## DATA GENERATION
x <- c(50, 62, 71, 75, 82, 90, 96, 102)
y <- c(38, 45, 60, 68, 70, 86, 88, 95)
#y <- c(35, 54, 72, 81, 91, 94, 97, 98)
table <- matrix(c(x,y), nrow = 2, byrow = T)
#decimals <- matrix(c(rep(0,6), rep(2,6)), nrow = 3, ncol=6, byrow=TRUE)
rownames(table) <- c("Dose (mg)", "Inflammation reduction (%)")
## QUESTION/ANSWER GENERATION
# colors  
col1 <- "#05A1E6"
# sample size
n <- length(x)
# means
mx <- mean(x)
mlogx <- mean(log(x))
my <- mean(y)
mlogy <- mean(log(y))
# variances
s2x <- sum(x^2)/n-mx^2
s2logx <- sum(log(x)^2)/n-mlogx^2
s2y <- sum(y^2)/n-my^2
s2logy <- sum(log(y)^2)/n-mlogy^2
# Covariances
sxy <- sum(x * y) / n - mx * my
sxlogy <- sum(x*log(y))/n-mx*mlogy
slogxy <- sum(log(x)*y)/n-mlogx*my
# Determination coeff
r2xy <-  sxy^2 / (s2x * s2y)
r2xlogy <- sxlogy^2/(s2x*s2logy)
r2logxy <- slogxy^2/(s2logx*s2y)
# Regression line of y on x
reglinyx <- lm(y ~ x)
# Regression line of x on y
reglinxy <- lm(x ~ y)
```

The following table shows the reduction of inflammation in trauma (in percentage) for different doses of dexketoprofen given for 4 days (in mg).

```{r}
kbl(table) %>%
    kable_styling(position = "center")
```

a.  Draw the scatter diagram of inflammation reduction versus dose of dexketoprofen.

a.  What percentage of inflammation reduction variability does the linear model explain? And the logarithmic model?

a.  According to the best of the two previous models, what is the expected percentage of inflammation reduction if we use 75 mg of dexketoprofen? Which dose should be administered to attain an inflammation reduction of 90%? Are these predictions reliable?

Use the following sums for the computation ($X$=Dose, $Y$=inflammation reduction):  
$\sum x_i=`r round(sum(x), 4)`$ mg, $\sum \log(x_i)=`r round(sum(log(x)), 4)`$ $\log(\mbox{mg})$, $\sum y_j=`r round(sum(y), 4)`$ %, $\sum \log(y_j)=`r round(sum(log(y)), 4)`$ $\log(\mbox{\%})$,  
$\sum x_i^2=`r round(sum(x^2), 2)`$ mg$^2$, $\sum \log(x_i)^2=`r round(sum(log(x)^2), 4)`$ $\log(\mbox{mg})^2$, $\sum y_j^2=`r round(sum(y^2), 4)`$ %$^2$, $\sum \log(y_j)^2=`r round(sum(log(y)^2), 4)`$ $\log(\mbox{\%})^2$,  
$\sum x_iy_j=`r round(sum(x*y), 4)`$ mg$\cdot$%, $\sum x_i\log(y_j)=`r round(sum(x*log(y)), 4)`$ mg$\cdot\log(\mbox{\%})$, $\sum \log(x_i)y_j=`r round(sum(log(x)*y), 4)`$ $\log(\mbox{mg})$%, $\sum \log(x_i)\log(y_j)=`r round(sum(log(x)*log(y)), 4)`$ $\log(\mbox{mg})\log(\mbox{\%})$.

:::{.callout-tip collapse="true"}
## Solution
a.  

```{r scatter plot}
plot(x, y, xlab = "Dose (mg)", ylab = "Inflammation reduction (%)", main = "Scatter plot of inflammation reduction on dose", col = "steelblue", pch=19)
```

a. **Linear model**  
$\bar x=`r round(mx,4)`$ mg, $s_x^2=`r round(s2x,4)`$ mg$^2$.  
$\bar y=`r round(my,4)`$ %, $s_y^2=`r round(s2y,4)`$ %$^2$.  
$s_{xy}=`r round(sxy,4)`$ mg$\cdot$ %.  
$r^2=`r round(r2xy,4)`$, so the linear model explains $`r round(r2xy,4)*100`$% of the variability of the inflammation reduction.  
**Logarithmic model**  
$\overline{\log(x)}=`r round(mlogx,4)`$ log(mg), $s_{\log(x)}^2=`r round(s2logx,4)`$ log(mg)$^2$.  
$s_{\log(x)y}=`r round(slogxy,4)`$ log(mg)$\cdot$%.  
$r^2=`r round(r2logxy,4)`$, so the logarithmic model explains $`r round(r2logxy,4)*100`$% of the variability of the inflammation reduction.

a.  The linear model fits better than the logarithmic one as its coefficient of determination is greater.  
Regression line of $Y$ on $X$: $y=`r round(reglinyx$coefficients[1],4)`+`r round(reglinyx$coefficients[2],4)`x$.    
Prediction: $y(75)=`r round(reglinyx$coefficients[1] + reglinyx$coefficients[2]*75,4)`$ %.  
Regression line of $X$ on $Y$: $x=`r round(reglinxy$coefficients[1],4)`+`r round(reglinxy$coefficients[2],4)`y$.    
Prediction: $x(90)=`r round(reglinxy$coefficients[1] + reglinxy$coefficients[2]*90,4)`$ mg.  
Although the linear coefficient of determination is close to 1, the sample size is too small to consider these predictions reliable.
:::
:::
